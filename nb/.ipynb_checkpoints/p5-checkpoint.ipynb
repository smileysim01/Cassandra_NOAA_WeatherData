{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07bb2eb1-921a-42ec-989a-ebb75ef8a3f8",
   "metadata": {},
   "source": [
    "# simran4@wisc.edu\n",
    "# rgundavarapu@wisc.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00bd637f-cfce-4622-940b-78084bcd6fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "try:\n",
    "    cluster = Cluster(['project-5-srh4dawin-db-1', 'project-5-srh4dawin-db-2', 'project-5-srh4dawin-db-3'])\n",
    "    cass = cluster.connect()\n",
    "    cass.execute(\"drop keyspace if exists weather\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b65d3bd-4736-4f23-8f41-e4ec6f1a6673",
   "metadata": {},
   "source": [
    "# Part 1: Station Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d93fcc0-29fe-46c6-bf8d-ca3a84f028f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7fc0439a7340>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATA SETUP\n",
    "\n",
    "cass.execute(\"\"\"\n",
    "CREATE KEYSPACE weather \n",
    "WITH REPLICATION = {\n",
    "    'class' : 'SimpleStrategy', \n",
    "    'replication_factor' : 3 \n",
    "    };\n",
    "\"\"\")\n",
    "\n",
    "cass.execute(\"\"\"\n",
    "CREATE TYPE \n",
    "    weather.station_record (tmin int, tmax int)\n",
    "\"\"\")\n",
    "\n",
    "cass.execute(\"\"\"\n",
    "CREATE TABLE weather.stations (\n",
    "    id text,\n",
    "    name text STATIC,\n",
    "    date date,\n",
    "    record weather.station_record,\n",
    "    state text,\n",
    "    PRIMARY KEY (id,date)\n",
    ") WITH CLUSTERING ORDER BY (date asc)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef42f683-e891-4538-98cb-a2e842909f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyspace_name</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>system</td>\n",
       "      <td>keyspace</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>system_auth</td>\n",
       "      <td>keyspace</td>\n",
       "      <td>system_auth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>system_distributed</td>\n",
       "      <td>keyspace</td>\n",
       "      <td>system_distributed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>system_schema</td>\n",
       "      <td>keyspace</td>\n",
       "      <td>system_schema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>system_traces</td>\n",
       "      <td>keyspace</td>\n",
       "      <td>system_traces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>system_views</td>\n",
       "      <td>keyspace</td>\n",
       "      <td>system_views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>system_virtual_schema</td>\n",
       "      <td>keyspace</td>\n",
       "      <td>system_virtual_schema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weather</td>\n",
       "      <td>keyspace</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           keyspace_name      type                   name\n",
       "0                 system  keyspace                 system\n",
       "1            system_auth  keyspace            system_auth\n",
       "2     system_distributed  keyspace     system_distributed\n",
       "3          system_schema  keyspace          system_schema\n",
       "4          system_traces  keyspace          system_traces\n",
       "5           system_views  keyspace           system_views\n",
       "6  system_virtual_schema  keyspace  system_virtual_schema\n",
       "7                weather  keyspace                weather"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(cass.execute(\"describe keyspaces\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64998efb-43bc-42c8-b41c-259779785511",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67e2c051-3f5a-40d6-88f5-a7dbfd51933e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE KEYSPACE weather WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '3'}  AND durable_writes = true;\n",
      "CREATE TABLE weather.stations (\n",
      "    id text,\n",
      "    date date,\n",
      "    name text static,\n",
      "    state text,\n",
      "    record station_record,\n",
      "    PRIMARY KEY (id, date)\n",
      ") WITH CLUSTERING ORDER BY (date ASC)\n",
      "    AND additional_write_policy = '99p'\n",
      "    AND bloom_filter_fp_chance = 0.01\n",
      "    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n",
      "    AND cdc = false\n",
      "    AND comment = ''\n",
      "    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\n",
      "    AND compression = {'chunk_length_in_kb': '16', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n",
      "    AND crc_check_chance = 1.0\n",
      "    AND default_time_to_live = 0\n",
      "    AND extensions = {}\n",
      "    AND gc_grace_seconds = 864000\n",
      "    AND max_index_interval = 2048\n",
      "    AND memtable_flush_period_in_ms = 0\n",
      "    AND min_index_interval = 128\n",
      "    AND read_repair = 'BLOCKING'\n",
      "    AND speculative_retry = '99p';\n"
     ]
    }
   ],
   "source": [
    "print(cass.execute(\"describe keyspace weather\").one().create_statement)\n",
    "print(cass.execute(\"describe table weather.stations\").one().create_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49a02e72-90b1-4e1f-9ff8-865790057162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.10/dist-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-be8c246c-65bc-4e74-96d8-8fbc7861fd79;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.datastax.spark#spark-cassandra-connector_2.12;3.2.0 in central\n",
      "\tfound com.datastax.spark#spark-cassandra-connector-driver_2.12;3.2.0 in central\n",
      "\tfound com.datastax.oss#java-driver-core-shaded;4.13.0 in central\n",
      "\tfound com.datastax.oss#native-protocol;1.5.0 in central\n",
      "\tfound com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central\n",
      "\tfound com.typesafe#config;1.4.1 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.26 in central\n",
      "\tfound io.dropwizard.metrics#metrics-core;4.1.18 in central\n",
      "\tfound org.hdrhistogram#HdrHistogram;2.1.12 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound com.github.stephenc.jcip#jcip-annotations;1.0-1 in central\n",
      "\tfound com.github.spotbugs#spotbugs-annotations;3.1.12 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound com.datastax.oss#java-driver-mapper-runtime;4.13.0 in central\n",
      "\tfound com.datastax.oss#java-driver-query-builder;4.13.0 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.10 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.11 in central\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/spark/spark-cassandra-connector_2.12/3.2.0/spark-cassandra-connector_2.12-3.2.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.spark#spark-cassandra-connector_2.12;3.2.0!spark-cassandra-connector_2.12.jar (140ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/spark/spark-cassandra-connector-driver_2.12/3.2.0/spark-cassandra-connector-driver_2.12-3.2.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.spark#spark-cassandra-connector-driver_2.12;3.2.0!spark-cassandra-connector-driver_2.12.jar (81ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-core-shaded/4.13.0/java-driver-core-shaded-4.13.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.oss#java-driver-core-shaded;4.13.0!java-driver-core-shaded.jar (291ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-mapper-runtime/4.13.0/java-driver-mapper-runtime-4.13.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.oss#java-driver-mapper-runtime;4.13.0!java-driver-mapper-runtime.jar(bundle) (22ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/commons/commons-lang3/3.10/commons-lang3-3.10.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.commons#commons-lang3;3.10!commons-lang3.jar (41ms)\n",
      "downloading https://repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar ...\n",
      "\t[SUCCESSFUL ] com.thoughtworks.paranamer#paranamer;2.8!paranamer.jar(bundle) (19ms)\n",
      "downloading https://repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.12.11/scala-reflect-2.12.11.jar ...\n",
      "\t[SUCCESSFUL ] org.scala-lang#scala-reflect;2.12.11!scala-reflect.jar (129ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/oss/native-protocol/1.5.0/native-protocol-1.5.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.oss#native-protocol;1.5.0!native-protocol.jar(bundle) (24ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-shaded-guava/25.1-jre-graal-sub-1/java-driver-shaded-guava-25.1-jre-graal-sub-1.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1!java-driver-shaded-guava.jar (57ms)\n",
      "downloading https://repo1.maven.org/maven2/com/typesafe/config/1.4.1/config-1.4.1.jar ...\n",
      "\t[SUCCESSFUL ] com.typesafe#config;1.4.1!config.jar(bundle) (19ms)\n",
      "downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.26/slf4j-api-1.7.26.jar ...\n",
      "\t[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.26!slf4j-api.jar (15ms)\n",
      "downloading https://repo1.maven.org/maven2/io/dropwizard/metrics/metrics-core/4.1.18/metrics-core-4.1.18.jar ...\n",
      "\t[SUCCESSFUL ] io.dropwizard.metrics#metrics-core;4.1.18!metrics-core.jar(bundle) (19ms)\n",
      "downloading https://repo1.maven.org/maven2/org/hdrhistogram/HdrHistogram/2.1.12/HdrHistogram-2.1.12.jar ...\n",
      "\t[SUCCESSFUL ] org.hdrhistogram#HdrHistogram;2.1.12!HdrHistogram.jar(bundle) (22ms)\n",
      "downloading https://repo1.maven.org/maven2/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar ...\n",
      "\t[SUCCESSFUL ] org.reactivestreams#reactive-streams;1.0.3!reactive-streams.jar (16ms)\n",
      "downloading https://repo1.maven.org/maven2/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar ...\n",
      "\t[SUCCESSFUL ] com.github.stephenc.jcip#jcip-annotations;1.0-1!jcip-annotations.jar (21ms)\n",
      "downloading https://repo1.maven.org/maven2/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar ...\n",
      "\t[SUCCESSFUL ] com.github.spotbugs#spotbugs-annotations;3.1.12!spotbugs-annotations.jar (17ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar ...\n",
      "\t[SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.2!jsr305.jar (15ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-query-builder/4.13.0/java-driver-query-builder-4.13.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.oss#java-driver-query-builder;4.13.0!java-driver-query-builder.jar(bundle) (19ms)\n",
      ":: resolution report :: resolve 6759ms :: artifacts dl 1002ms\n",
      "\t:: modules in use:\n",
      "\tcom.datastax.oss#java-driver-core-shaded;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-mapper-runtime;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-query-builder;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]\n",
      "\tcom.datastax.oss#native-protocol;1.5.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector-driver_2.12;3.2.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector_2.12;3.2.0 from central in [default]\n",
      "\tcom.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]\n",
      "\tcom.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from central in [default]\n",
      "\tcom.typesafe#config;1.4.1 from central in [default]\n",
      "\tio.dropwizard.metrics#metrics-core;4.1.18 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.10 from central in [default]\n",
      "\torg.hdrhistogram#HdrHistogram;2.1.12 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.11 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.26 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   18  |   18  |   18  |   0   ||   18  |   18  |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-be8c246c-65bc-4e74-96d8-8fbc7861fd79\n",
      "\tconfs: [default]\n",
      "\t18 artifacts copied, 0 already retrieved (18065kB/131ms)\n",
      "23/04/15 02:20:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"p5\")\n",
    "         .config('spark.jars.packages', 'com.datastax.spark:spark-cassandra-connector_2.12:3.2.0')\n",
    "         .config(\"spark.sql.extensions\", \"com.datastax.spark.connector.CassandraSparkExtensions\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11e7d8e8-69ca-49f3-b7b9-a38d31a4a8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 10.1M  100 10.1M    0     0  19.2M      0 --:--:-- --:--:-- --:--:-- 19.3M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "!curl 'https://pages.cs.wisc.edu/~harter/cs639/data/ghcnd-stations.txt' > ghcnd-stations.txt\n",
    "df = spark.read.text(\"ghcnd-stations.txt\")\n",
    "df.write.saveAsTable('stations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1311e9f-82c7-4bc6-8a6e-95a08d4cb1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "metadata=spark.sql(\"\"\"\n",
    "SELECT SUBSTRING(value,0,11) as id,SUBSTRING(value,42,30) as name\n",
    "FROM stations\n",
    "WHERE SUBSTRING(value,39,2) == 'WI'\n",
    "\"\"\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1d02ef7-b4ad-4b57-aff0-ec021fb4321f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_table():\n",
    "    return pd.DataFrame(cass.execute(\"select * from weather.stations\"))\n",
    "show_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de17b204-45f3-4629-9d7c-9b76179a8d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_weather_stations = cass.prepare(\"\"\"\n",
    "INSERT INTO weather.stations\n",
    "(id,name)\n",
    "VALUES\n",
    "(?,?)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8e0b67e-15bb-4c03-9eb9-4dad5ccb3a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>record</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USC00479053</td>\n",
       "      <td>None</td>\n",
       "      <td>W BEND FIRE STN #2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USC00476398</td>\n",
       "      <td>None</td>\n",
       "      <td>PARK FALLS DNR HQ</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USC00470268</td>\n",
       "      <td>None</td>\n",
       "      <td>APPOLONIA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USC00474110</td>\n",
       "      <td>None</td>\n",
       "      <td>JUNEAU</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USC00475525</td>\n",
       "      <td>None</td>\n",
       "      <td>MINONG 5 WSW</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>USC00479050</td>\n",
       "      <td>None</td>\n",
       "      <td>WEST BEND</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>US1WIPC0004</td>\n",
       "      <td>None</td>\n",
       "      <td>RIVER FALLS 3.0 SE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>US1WIWK0016</td>\n",
       "      <td>None</td>\n",
       "      <td>MUSKEGO 1.0 W</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>US1WIWK0086</td>\n",
       "      <td>None</td>\n",
       "      <td>WALES 0.4 NW</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>USC00475471</td>\n",
       "      <td>None</td>\n",
       "      <td>MIDDLETON</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1313 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  date                            name record state\n",
       "0     USC00479053  None  W BEND FIRE STN #2               None  None\n",
       "1     USC00476398  None  PARK FALLS DNR HQ                None  None\n",
       "2     USC00470268  None  APPOLONIA                        None  None\n",
       "3     USC00474110  None  JUNEAU                           None  None\n",
       "4     USC00475525  None  MINONG 5 WSW                     None  None\n",
       "...           ...   ...                             ...    ...   ...\n",
       "1308  USC00479050  None  WEST BEND                        None  None\n",
       "1309  US1WIPC0004  None  RIVER FALLS 3.0 SE               None  None\n",
       "1310  US1WIWK0016  None  MUSKEGO 1.0 W                    None  None\n",
       "1311  US1WIWK0086  None  WALES 0.4 NW                     None  None\n",
       "1312  USC00475471  None  MIDDLETON                        None  None\n",
       "\n",
       "[1313 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in metadata:\n",
    "    cass.execute(insert_weather_stations,(i[0],i[1]))\n",
    "show_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d848205-2158-4e55-b96f-25132d2c4588",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "609dccd2-7750-4bde-8560-f06b88aef0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9014250178872933741"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in list(cass.execute(\"\"\"\n",
    "select id,token(id) from weather.stations  \n",
    "\"\"\")):\n",
    "    if i[0] == 'USC00470273':\n",
    "        row_token = i[1]\n",
    "row_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8daa6241-276a-407c-bbbf-4a6a282993ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8701723725492472883"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "output= (subprocess.check_output([\"nodetool\",\"ring\"])).decode().split('\\n')\n",
    "for i in output[5:53]:    ## loop over output and check for value that is greater than data token\n",
    "    v_node=int(i[70:])\n",
    "    if(v_node>=row_token):\n",
    "        vnode_token = v_node\n",
    "        break\n",
    "vnode_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c835f45e-e7bb-4dde-8ce4-901f62569ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row token:  -9014250178872933741\n",
      "vnode token:  -8701723725492472883\n"
     ]
    }
   ],
   "source": [
    "print(f'row token: ',row_token)\n",
    "print(f'vnode token: ',vnode_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f75daa4-e7dc-4982-9f25-a0ac244f0a93",
   "metadata": {},
   "source": [
    "# Part 2:Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7c8d292-c867-4411-b1d0-4a335fd3e14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  126M  100  126M    0     0  71.0M      0  0:00:01  0:00:01 --:--:-- 71.0M    0  63.4M      0  0:00:02  0:00:01  0:00:01 63.3M\n"
     ]
    }
   ],
   "source": [
    "!curl https://pages.cs.wisc.edu/~harter/cs639/data/wi-stations.zip > wi-stations.zip\n",
    "import zipfile as zf\n",
    "zf.ZipFile('wi-stations.zip').extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7b314a0-fa7a-4fc6-af14-9035124951a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "_InactiveRpcError",
     "evalue": "<_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"Exception calling application: meow.RecordTemps() missing 2 required positional arguments: 'tmin' and 'tmax'\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:172.27.0.4:5440 {created_time:\"2023-04-15T03:17:46.385726998+00:00\", grpc_status:2, grpc_message:\"Exception calling application: meow.RecordTemps() missing 2 required positional arguments: \\'tmin\\' and \\'tmax\\'\"}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m         stub\u001b[38;5;241m.\u001b[39mRecordTemps(station_pb2\u001b[38;5;241m.\u001b[39mRecordTempsRequest(station\u001b[38;5;241m=\u001b[39mstation,date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(i[\u001b[38;5;241m0\u001b[39m]),tmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(i[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]),tmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(i[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m])))\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m station \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSW00014837\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSR0000WDDG\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSW00014898\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSW00014839\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m---> 21\u001b[0m     \u001b[43msimulate_sensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     r \u001b[38;5;241m=\u001b[39m stub\u001b[38;5;241m.\u001b[39mStationMax(station_pb2\u001b[38;5;241m.\u001b[39mStationMaxRequest(station\u001b[38;5;241m=\u001b[39mstation))\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39merror:\n",
      "Cell \u001b[0;32mIn[46], line 18\u001b[0m, in \u001b[0;36msimulate_sensor\u001b[0;34m(station)\u001b[0m\n\u001b[1;32m     16\u001b[0m hello\u001b[38;5;241m=\u001b[39mhello\u001b[38;5;241m.\u001b[39mpivot(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_c2\u001b[39m\u001b[38;5;124m'\u001b[39m,values\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_c3\u001b[39m\u001b[38;5;124m'\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m hello\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mstub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRecordTemps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstation_pb2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRecordTempsRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstation\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py:1030\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1022\u001b[0m              request: Any,\n\u001b[1;32m   1023\u001b[0m              timeout: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1026\u001b[0m              wait_for_ready: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1027\u001b[0m              compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1028\u001b[0m     state, call, \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(request, timeout, metadata, credentials,\n\u001b[1;32m   1029\u001b[0m                                   wait_for_ready, compression)\n\u001b[0;32m-> 1030\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py:910\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m state\u001b[38;5;241m.\u001b[39mresponse\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 910\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"Exception calling application: meow.RecordTemps() missing 2 required positional arguments: 'tmin' and 'tmax'\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:172.27.0.4:5440 {created_time:\"2023-04-15T03:17:46.385726998+00:00\", grpc_status:2, grpc_message:\"Exception calling application: meow.RecordTemps() missing 2 required positional arguments: \\'tmin\\' and \\'tmax\\'\"}\"\n>"
     ]
    }
   ],
   "source": [
    "import station_pb2_grpc, station_pb2, grpc\n",
    "import pandas as pd\n",
    "import datetime\n",
    "channel = grpc.insecure_channel('ac6741bcd4fe:5440')\n",
    "stub = station_pb2_grpc.StationStub(channel)\n",
    "def simulate_sensor(station):\n",
    "    # TODO: loop over tmin/tmax data for every day of 2022 for the given station;\n",
    "    # send each to server with RecordTemps call\n",
    "    df = spark.read.format(\"csv\").option(\"compression\", \"gzip\").load(f'{station}.csv.gz')\n",
    "    df.write.saveAsTable(f'{station}', mode='overwrite')\n",
    "    hello=spark.sql(f\"\"\" \n",
    "    select *,SUBSTRING(_c1,0,4) as year,concat(SUBSTRING(_c1,0,4),'-',SUBSTRING(_c1,5,2),'-',SUBSTRING(_c1,7,2)) as date \n",
    "    from {station}\n",
    "    where SUBSTRING(_c1,0,4) == 2022 and (_c2 =='TMIN' or _c2=='TMAX')\n",
    "    \"\"\").toPandas()\n",
    "    hello=hello.pivot(columns='_c2',values='_c3',index='date')\n",
    "    for i in hello.iterrows():\n",
    "        stub.RecordTemps(station_pb2.RecordTempsRequest(station=station,date=str(i[0]),tmin=int(i[1][0]),tmax=int(i[1][1])))\n",
    "\n",
    "for station in [\"USW00014837\", \"USR0000WDDG\", \"USW00014898\", \"USW00014839\"]:\n",
    "    simulate_sensor(station)\n",
    "    r = stub.StationMax(station_pb2.StationMaxRequest(station=station))\n",
    "    if r.error:\n",
    "        print(r.error)\n",
    "    else:\n",
    "        print(f\"max temp for {station} is {r.tmax}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "579cd2ba-e821-4e30-a119-5641004f2d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>record</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USC00479053</td>\n",
       "      <td>None</td>\n",
       "      <td>W BEND FIRE STN #2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USC00476398</td>\n",
       "      <td>None</td>\n",
       "      <td>PARK FALLS DNR HQ</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USC00470268</td>\n",
       "      <td>None</td>\n",
       "      <td>APPOLONIA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USC00474110</td>\n",
       "      <td>None</td>\n",
       "      <td>JUNEAU</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USC00475525</td>\n",
       "      <td>None</td>\n",
       "      <td>MINONG 5 WSW</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>USC00479050</td>\n",
       "      <td>None</td>\n",
       "      <td>WEST BEND</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>US1WIPC0004</td>\n",
       "      <td>None</td>\n",
       "      <td>RIVER FALLS 3.0 SE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>US1WIWK0016</td>\n",
       "      <td>None</td>\n",
       "      <td>MUSKEGO 1.0 W</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>US1WIWK0086</td>\n",
       "      <td>None</td>\n",
       "      <td>WALES 0.4 NW</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>USC00475471</td>\n",
       "      <td>None</td>\n",
       "      <td>MIDDLETON</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1313 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  date                            name record state\n",
       "0     USC00479053  None  W BEND FIRE STN #2               None  None\n",
       "1     USC00476398  None  PARK FALLS DNR HQ                None  None\n",
       "2     USC00470268  None  APPOLONIA                        None  None\n",
       "3     USC00474110  None  JUNEAU                           None  None\n",
       "4     USC00475525  None  MINONG 5 WSW                     None  None\n",
       "...           ...   ...                             ...    ...   ...\n",
       "1308  USC00479050  None  WEST BEND                        None  None\n",
       "1309  US1WIPC0004  None  RIVER FALLS 3.0 SE               None  None\n",
       "1310  US1WIWK0016  None  MUSKEGO 1.0 W                    None  None\n",
       "1311  US1WIWK0086  None  WALES 0.4 NW                     None  None\n",
       "1312  USC00475471  None  MIDDLETON                        None  None\n",
       "\n",
       "[1313 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e389bd0-864a-4395-9e34-027d6c469069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile as zf\n",
    "zf.ZipFile('wi-stations.zip').extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93007f78-0739-40f9-838f-15a0b80eb018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"compression\", \"gzip\").load('USW00014837.csv.gz')\n",
    "df.write.saveAsTable('USW00014837', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44f1434-38f8-4b9c-a7e2-e74f9c18cf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\" \n",
    "select _c3,SUBSTRING(_c1,0,4) as year,concat(SUBSTRING(_c1,0,4),'-',SUBSTRING(_c1,5,2),'-',SUBSTRING(_c1,7,2)) as date \n",
    "from USW00014837\n",
    "where SUBSTRING(_c1,0,4) == 2022 and _c2 =='TMAX'\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd27f799-b2f8-426f-8670-8235f7630da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hello=spark.sql(f\"\"\" \n",
    "select *,SUBSTRING(_c1,0,4) as year,concat(SUBSTRING(_c1,0,4),'-',SUBSTRING(_c1,5,2),'-',SUBSTRING(_c1,7,2)) as date \n",
    "from USW00014837\n",
    "where SUBSTRING(_c1,0,4) == 2022 and (_c2 =='TMIN' or _c2=='TMAX')\n",
    "\"\"\").toPandas()\n",
    "hello=hello.pivot(columns='_c2',values='_c3',index='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5f8334-3a0a-484c-aedb-9f7187c36980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "for i in hello.iterrows():\n",
    "    print(int(i[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fc80de-1136-41c5-8b53-1064f137b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in hello.iterrows():\n",
    "    print(i[0],i[1][1],i[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9a80e5-75c3-4d8d-ad24-2f7262c1fea4",
   "metadata": {},
   "outputs": [],
   "source": [
    ".pivot(\"element\", [\"TMIN\", \"TMAX\"])\n",
    "INSERT INTO weather.stations (id, date, record) VALUES (?, ?, {tmin:?, tmax:?})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
